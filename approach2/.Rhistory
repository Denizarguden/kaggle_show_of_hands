lm(yValues ~ ns1)
library(tree)
lm1 <- lm(y ~ ., data = trainData)
rmse(predict(lm1, data = testData), testData$y)
install.packages("devtools")
library("devtools")
library(devtools)
install_github("medley", "mewo2")
library(medley)
myModel1 <- lm(yValues ~ ns1)
rmse(predict(myModel, data = xValues), yValues)
library(splines)
ns1 <- ns(xValues, df = 1)
myModel1 <- lm(yValues ~ ns1)
rmse(predict(myModel, data = xValues), yValues)
library(splines)
ns1 <- ns(xValues, df = 1)
myModel1 <- lm(yValues ~ ns1)
rmse(predict(myModel1, data = yValues), yValues)
rmse(predict(myModel1, data = xValues), yValues)
ns2 <- ns(xValues, df = 2)
myModel1 <- lm(yValues ~ ns2)
myModel2 <- lm(yValues ~ ns2)
rmse(predict(myModel2, data = yValues), yValues)
rmse(predict(myModel3, data = yValues), yValues)
myModel3 <- lm(yValues ~ ns3)
ns3 <- ns(xValues, df = 3)
myModel3 <- lm(yValues ~ ns3)
rmse(predict(myModel3, data = yValues), yValues)
library(tree)
lm1 <- lm(y ~ ., data = trainData)
library(simpleboot)
library(simpleboot)
install.packages(simpleboot)
install.packages("simpleboot"")
install.packages("simpleboot")
install.packages("simpleboot")
library(simpleboot)
install.packages("boot")
install.packages("boot")
library(simpleboot)
data(airquality)
attach(airquality)
boot1 = one.boot(airquality$Wind, b.fun, R = 1000)
set.seed(53535)
xValues = seq(0,2*pi,length=100)
yValues = rnorm(100) + sin(xValues)
library(splines)
?predict
ns1 <- ns(xValues, df = 1)
myModel1 <- lm(yValues ~ ns1)
rmse(predict(myModel1, data = yValues), yValues)
library(splines)
ns1 <- ns(xValues, df = 1)
myModel1 <- lm(yValues ~ ns1)
rmse(predict(myModel1, data = yValues), yValues)
library(medley)
library(e1071)
library(devtools)
install_github("medley", "mewo2")
library(medley)
library(e1071)
library(randomForests)
myModel1 <- lm(yValues ~ ns1)
rmse(predict(myModel1, data = yValues), yValues)
ns2 <- ns(xValues, df = 2)
myModel2 <- lm(yValues ~ ns2)
rmse(predict(myModel2, data = yValues), yValues)
ns3 <- ns(xValues, df = 3)
myModel3 <- lm(yValues ~ ns3)
rmse(predict(myModel3, data = yValues), yValues)
rmse(predict(myModel1, data = xValues), yValues)
rmse(predict(myModel2, data = xValues), yValues)
rmse(predict(myModel3, data = xValues), yValues)
attach(airquality)
data(airquality)
head(airquality)
lm.b <- lm(fit ~ Wind, data = airquality)
lm.b <- lm(Wind ~ Wind, data = airquality)
x <- rnorm(30)
length(x)
y <- sample(x, replace = TRUE)
length(y)
mean(x)
mean(y)
?data.frame
col1_data <- c(50, 5, 55)
col2_data <- c(10, 20, 30)
col3_data <- c(60, 25, 85)
df <- data.frame(col1_data)
df
df <- data.frame(col1_data, col2_data)
df
df <- data.frame(col1_data, col2_data, col3_data)
df
column.names
names(df)
col1_name <- "b = 0"
col2_name <- "b =/ 0"
col3_name <- "Claims Total"
names(df) <- c(col1_name, col2_name, col3_name)
df
col.names(df) <- c(col1_name, col2_name, col3_name)
colnames(df) <- c(col1_name, col2_name, col3_name)
df
rownames(df) <- c(row1_name, row2_name, row3_name)
row1_name <- "Claim b = 0"
row2_name <- "Claim b =/ 0"
row3_name <- "Hypothesis Totals"
rownames(df) <- c(row1_name, row2_name, row3_name)
df
df
5 / 55
10 / 30
set.seed(3343)
pValues = rep(NA,100)
for(i in 1:100){
z = rnorm(20)
x = rnorm(20)
y = rnorm(20,mean=0.5*x)
pValues[i] = summary(lm(y ~ x))$coef[2,4]
}
summary(lm(y~x))$coef[2, 4]
summary(lm(y~x))
summary(lm(y~x))$coef
summary(lm(y~x))$coef[1]
summary(lm(y~x))$coef[2]
summary(lm(y~x))$coef[2, 4]
summary(lm(y~x))$coef[3]
summary(lm(y~x))$coef[4]
summary(lm(y~x))$coef[1, 4]
head(pValues)
plot(x, y)
lm <- lm(y ~ x)
lines(x, lm$fitted)
summary(lm(y ~ x))$coeff
summary(lm(y ~ x))
sum(pValues < 0.05)
sum(p.adjust(pValues, method = "BH") < 0.05)
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
pValues[100]
summary(lm(y ~ x))$coeff
summary(lm(y ~ x))$coeff[1, 4]
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
sum(p.adjust(pValues, method = "BH") < 0.05)
sum(pValues < 0.01)
sum(p.adjust(pValues, method = "bonferroni") < 0.01)
sum(p.adjust(pValues, method = "BH") < 0.01)
set.seed(3343)
pValues = rep(NA,100)
for(i in 1:100){
z = rnorm(20)
x = rnorm(20)
y = rnorm(20,mean=0.5*x)
pValues[i] = summary(lm(y ~ x))$coef[2,4]
}
sum(pValues < 0.01)
sum(p.adjust(pValues, method = "bonferroni") < 0.01)
sum(p.adjust(pValues, method = "BH") < 0.01)
sum(pValues < 0.1)
sum(p.adjust(pValues, method = "bonferroni") < 0.1)
sum(p.adjust(pValues, method = "BH") < 0.1)
2 + 2
print("hello")
pwd
pwd
.
is_vector <- c(11, 13, 17, 19, 23)
matmaker_list <- vector('list', length(is_vector))
is_vector
matmaker_list
for (i in 1:length(is_vector)) {
matmaker_list[[i]] <- 0:1
}
matmaker_list
expand.grid(0:1, 1:2)
expand.grid(0:1, 1:3)
expand.grid(matmaker_list)
dim(matmaker_list)
dims(matmaker_list)
matmaker_list
matmaker_list
expand.grid(matmaker_list)
matmaker_list
combos_matrix <- expand.grid(matmaker_list)
expand.grid(matmaker_list)
class(combos_matrix)
t(combos_matrix)
is_vector %*% t(combos_matrix)
answer <- is_vector %*% t(combos_matrix)
unique(sort(answer))
install.package('ggplot2')
install.packages('ggplot2')
library('ggplot2')
head(diamonds)
str(diamonds) # str for structure
names(diamonds)
p + geom_histogram()
p <- ggplot(diamonds, aes=(x=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes=(x = clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes=(clarity))
p + geom_histogram()
library('ggplot2')
p <- ggplot(diamonds, aes=(x=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes=(x=clarity, y=1))
p + geom_histogram()
help(ggplot)
install.packages('ggplot2')
install.packages("ggplot2")
install.packages("ggplot2")
library('ggplot2')
p <- ggplot(diamonds, aes=(x=clarity))
p + geom_histogram()
help(ggplot)
p <- ggplot(diamonds, aes=(y=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes = ( y = clarity ))
p + geom_histogram()
getwd()
head(diamonds)
str(diamonds) # str for structure
names(diamonds)
# plot preparation
p <- ggplot(diamonds, aes=(y=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes(y=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity, fill=cut))
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity, fill=cut), main='hi')
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity, fill=cut))
p + geom_histogram() + opts(title='Chart')
p + geom_histogram() + labs(title='Chart')
head(mtcars)
length(mtcars)
mtcars
head(mtcars)
names(mtcars)
p <- qplot(wt, mpg, data=mtcars)
p + geom_abline()
coeff(lm(mpg ~ wt), data=mtcars)
coef(lm(mpg ~ wt), data=mtcars)
coef(lm(mpg ~ wt, data=mtcars))
p + geom_abline(intercept=37.285, slope=-5.344)
p + geom_abline(intercept=20)
p + geom_abline(intercept=37.285, slope=-5.344)
p + geom_abline(intercept = 10, colour = "red", size = 2)
p + geom_abline(intercept = 10, color = "red", size = 2)
p + geom_abline(intercept=37.285, slope=-5.344)
p + geom_abline(intercept = 10, color = "red", size = 2)
map_data("nz")
install.packages('psych')
search()
?data.frame
numbers <- 1:10
words <- c('one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten')
nw <- cbind(numbers, words)
nw
attributes(nw)
nw
nw$numbers
nw[8, 1]
nw[8, 2]
matrix(1:10, c(2, 5))
x <- 1:6
y <- 5:10
class(rbind(x, y))
rnorm(1, 6043834, 6823984)
rnorm(51, 6043834, 6823984)
hist(rnorm(51, 6043834, 6823984))
library(ggplot2)
library(maps)
install.packages('maps')
all_states <- map_data('state')
p <- ggplot()
p <- p + geom_polygon(data=all_states, aes(x=long, y=lat, group=group), color='white', fill='grey10')
p
world <- map_data('nation')
world <- map_data('country')
world <- map_data('world')
all_states
head(all_states)
unique(group)
unique(all_states$group)
nrow(all_states)
states <- subset(all_states,
region %in% c( "illinois",
"indiana",
"iowa",
"kentucky",
"michigan",
"minnesota",
"missouri",
"north dakota",
"ohio",
"south dakota",
"wisconsin" ))
p <- ggplot()
p <- p + geom_polygon(data=states,
aes(x=long, y=lat, group=group),
color='white',
fill='grey10')
p
getwd()
set.seed(31)
heightCM = rnorm(30, mean=188, sd=5)
weightsK = rnorm(30, mean=84, sd=3)
hasDaughter = sample(c(TRUE, FALSE), size=30, replace=T)
dataFrame = data.frame(heightsCM, weightsK, hasDaughter)
dataFrame = data.frame(heightCM, weightsK, hasDaughter)
names(dataFrame)
subset <- dataFrame[, dataFrame$heightCM >= 188]
condition <- dataFrame$heightCM >= 188
condition
subset <- dataFrame[condition, ]
getwd()
mean(subset$weightsK)
set.seed(41)
install.packages('tseries')
library(tseries)
library(tseries)
data(bev)
bev
data(nino)
nino
data(tcm)
tcm
?rm.packages()
?remove.packages()
?remove.packages(tseries)
remove.packages(tseries)
remove.packages('tseries')
library(ISLR)
set.seed(1)
train = sample(392, 196)
head(train)
length(train)
lm.fit <- lm(mpg ~ horsepower, data=Auto, subset=train)
attach(Auto)
length(predict(lm.fit))
length(mpg)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
(mpg - predict(lm.fit, Auto))[-train]^2
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data=Auto, subset=train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
library(boot)
glm.fit = glm(mpg ~ horsepower, data=Auto)
cv.error = cv.glm(Auto, glm.fit)
cv.error$delta
cv.error = rep(0, 5)
for (i in 1:5) {
glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 = rep(0, 10)
for (i in 10) {
glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
for (i in 1:10) {
glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
head(Portfolio)
?Portfolio
summary(Portfolio)
alpha.fn = function(data, index) {
X = data$X[index]
Y = data$Y[index]
return((var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y)))
}
alpha.fn(Portfolio, 1:1000)
alpha.fn(Portfolio, 1:100)
X = data$X[1:100]
boot(Portfolio, alpha.fn, R=1000)
boot.fn = function(data, index) {
return(coef(lm(mpg ~ horsepower, data=data, subset=index)))
}
head(Auto)
names(Auto)
dim(Auto)
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace=T))
boot.fn(Auto, sample(392, 392, replace=T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data=Auto))$coef
?I
boot.fn = function(data, index) {
return(coef(lm(mpg ~ horsepower + I(horsepower^2), data=data, subset=Index)))
}
set.seed(1)
boot(Auto, boot.fn, 1000)
boot.fn = function(data, index) {
return(coef(lm(mpg ~ horsepower + I(horsepower^2), data=data, subset=index)))
}
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower + I(horsepower^2), data=data))$coef
summary(lm(mpg ~ horsepower + I(horsepower^2), data=Auto))$coef
install.packages("shiny")
library(shiny)
a <- matrix(1:10, 5, 2)
a
a <- matrix(c(0.338, 0.391, 0.369, 0.313, 0.361, ))
a <- matrix(c(0.338, 0.391, 0.369, 0.313, 0.361, 0.54, 0.45, 0.374, 0.447, 0.5))
a <- matrix(c(0.338, 0.391, 0.369, 0.313, 0.361, 0.54, 0.45, 0.374, 0.447, 0.5), 5, 2)
a
b <- matrix(c(2737.77, 1584.91))
b
a * b
a %*% b
c <- a %*% b
c - 804.63
c <- c - 804.63
c
d <- matrix(c(1400000, 1065000, 295000, 800000, 300000))
d % c
d / c
teamRank = c(1,2,3,3,4,4,4,4,5,5)
r2012 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
r2013 <- c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
cor(teamRank, r2012)
cor(teamRank, r2013)
3 / 3
1 / 3
1 % 3
1 // 3
1 / 3
class(1 / 3)
class(3 / 3)
?%%
?%%
1 %% 3
2 %% 3
3 %% 3
1 %% 2
2 %% 3
2 %% 2
3 %% 2
15 %% 15
12 %% 15
for (i in 1:100) {
if (i %% 15 == 0) {
if (i %% 3 != 0 | i %% 5 != 0) {
next
}
else {
print('CracklePop')
}
}
else if (i %% 3 == 0) {
print('Crackle')
}
else if (i %% 5 == 0) {
print('Pop')
}
else {
print(i)
}
}
#### setting up working directory
rm(list=ls())
getwd()
setwd('/Users/hawooksong/Desktop/kaggle_show_of_hands')
dir()
#### loading data
# credit to: https://github.com/wehrley/wehrley.github.io/blob/master/SOUPTONUTS.md
initial_train_test.data.file <- "data/initial_train_test.csv"
final_test.data.file <- "data/final_test.csv"
missing.types <- c("NA", "")
initial_train_test.column.types <- c('integer',   # UserId
'integer',   # YOB (year of birth)
'factor',    # Gender
'factor',    # Income
'factor',    # HouseholdStatus
'factor',    # EducationLevel
'factor',    # Party
'integer',   # Happy
rep('factor', 101), # Questions (w/ binary answers)
'integer')   # votes
final_test.column.types <- initial_train_test.column.types[-8]
?read.csv
initial_train_test <- read.csv(initial_train_test.data.file,
na.strings = missing.types,
colClasses = initial_train_test.column.types)
final_test <- read.csv(final_test.data.file,
na.strings = missing.types,
colClasses = final_test.column.types)
table(is.na(initial_train_test))
table(is.na(initial_train_test))$TRUE
table(is.na(subset(initial_train_test, select = c(- Happy - UserID - votes)))
)
x <- subset(initial_train_test, select = c(- Happy, - UserID - votes))
head(x)
x <- subset(initial_train_test, select = c(- Happy, - UserID, - votes))
head(x)
table(is.na(subset(initial_train_test, select = c(- Happy, - UserID, - votes))))
139414 / (354819 + 139414)
